{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15061417-4774-43f6-95e3-70452e7f55bc",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unmatched ')' (2749630923.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[1], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    Ques1) To define a Python script that fetches the web page contents and parses it using Beautiful Soup to generate a soup object.\u001b[0m\n\u001b[1;37m         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unmatched ')'\n"
     ]
    }
   ],
   "source": [
    "Ques1) To define a Python script that fetches the web page contents and parses it using Beautiful Soup to generate a soup object.\n",
    "      You can use different selectors with the soup object to find elements on the web page and extract the desired information from it?\n",
    "\n",
    "\n",
    "Ans1)  import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def fetch_webpage(url):\n",
    "    \"\"\"Fetch the content of a web page and return a BeautifulSoup object.\"\"\"\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "    }\n",
    "    response = requests.get(url, headers=headers)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        return BeautifulSoup(response.text, 'html.parser')\n",
    "    else:\n",
    "        print(f\"Error: Unable to fetch the webpage, status code {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "def extract_information(soup):\n",
    "    \"\"\"Extracts and prints information from the soup object.\"\"\"\n",
    "    links = soup.find_all('a')\n",
    "    print(\"Links on the page:\")\n",
    "    for link in links[:10]:  # Print only the first 10 links\n",
    "        print(link.get('href'))\n",
    "    paragraphs = soup.find_all('p')\n",
    "    print(\"\\nParagraphs on the page:\")\n",
    "    for para in paragraphs[:5]:  # Print only the first 5 paragraphs\n",
    "        print(para.text)\n",
    "    headings = soup.find_all('h2', class_='example-class')\n",
    "    print(\"\\nHeadings with class 'example-class':\")\n",
    "    for heading in headings:\n",
    "        print(heading.text)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    url = \"https://example.com\"  # Replace with the target URL\n",
    "    soup = fetch_webpage(url)\n",
    "    \n",
    "    if soup:\n",
    "        extract_information(soup)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
